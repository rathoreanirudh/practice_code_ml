{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 5: Boosting and PCA\n",
    "\n",
    "\n",
    "This assignment is due on Moodle by **11:59pm on Friday November 22**. \n",
    "Your solutions to theoretical questions should be done in Markdown/MathJax directly below the associated question.\n",
    "Your solutions to computational questions should include any specified Python code and results \n",
    "as well as written commentary on your conclusions.\n",
    "Remember that you are encouraged to discuss the problems with your instructors and classmates, \n",
    "but **you must write all code and solutions on your own**. For a refresher on the course **Collaboration Policy** click [here](https://github.com/BoulderDS/CSCI5622-Machine-Learning/blob/master/info/syllabus.md#collaboration-policy).\n",
    "\n",
    "**NOTES**: \n",
    "\n",
    "- Do **NOT** load or use any Python packages that are not available in Anaconda (Version: 2019.07) with Python 3.7. \n",
    "- Some problems with code may be autograded.  If we provide a function API **do not** change it.  If we do not provide a function API then you're free to structure your code however you like. \n",
    "- Submit only this Jupyter notebook to Moodle.  Do not compress it using tar, rar, zip, etc.\n",
    "- **Unzip the files in data folder**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pickle\n",
    "import gzip\n",
    "import numpy as np\n",
    "import pandas\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[40 points] Problem 1 - Principal Component Analysis\n",
    "---\n",
    "\n",
    "In this problem you'll be implementing Dimensionality reduction using Principal Component Analysis technique. \n",
    "\n",
    "The gist of PCA Algorithm to compute principal components is follows:\n",
    "- Calculate the covariance matrix X of data points.\n",
    "- Calculate eigenvectors and corresponding eigenvalues.\n",
    "- Sort the eigenvectors according to their eigenvalues in decreasing order.\n",
    "- Choose first k eigenvectors which satisfies target explained variance.\n",
    "- Transform the original n dimensional data points into k dimensions.\n",
    "\n",
    "The skeleton for the `PCA` class is below. Scroll down to find more information about your tasks as well as unit tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5094f6ec40a765a6e8282dd78b0cc6ae",
     "grade": false,
     "grade_id": "cell-34ffc5741eeb12ad",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "class PCA:\n",
    "    def __init__(self, target_explained_variance=None):\n",
    "        \"\"\"\n",
    "        explained_variance: float, the target level of explained variance\n",
    "        \"\"\"\n",
    "        self.target_explained_variance = target_explained_variance\n",
    "        self.feature_size = -1\n",
    "\n",
    "    def standardize(self, X):\n",
    "        \"\"\"\n",
    "        standardize features using standard scaler\n",
    "        :param m X n: features data\n",
    "        :return: standardized features\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def compute_mean_vector(self, X_std):\n",
    "        \"\"\"\n",
    "        compute mean vector\n",
    "        :param X_std: data\n",
    "        :return n X 1 matrix: mean vector\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def compute_cov(self, X_std, mean_vec):\n",
    "        \"\"\"\n",
    "        Covariance using mean, (don't use any numpy.cov)\n",
    "        :param X_std:\n",
    "        :param mean_vec:\n",
    "        :return n X n matrix:: covariance matrix\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def compute_eigen_vector(self, cov_mat):\n",
    "        \"\"\"\n",
    "        Eigenvector and eigen values using numpy\n",
    "        :param cov_mat:\n",
    "        :return: (eigen_vector,eigen_values)\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def compute_explained_variance(self, eigen_vals):\n",
    "        \"\"\"\n",
    "        sort eigen values and compute explained variance.\n",
    "        explained variance informs the amount of information (variance)\n",
    "        can be attributed to each of  the principal components.\n",
    "        :param eigen_vals:\n",
    "        :return: explained variance.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def cumulative_sum(self, var_exp):\n",
    "        \"\"\"\n",
    "        return cumulative sum of explained variance.\n",
    "        :param var_exp: explained variance\n",
    "        :return: cumulative explained variance\n",
    "        \"\"\"\n",
    "        return np.cumsum(var_exp)\n",
    "\n",
    "    def compute_weight_matrix(self, eig_pairs, var_exp):\n",
    "        \"\"\"\n",
    "        compute weight matrix of top principal components conditioned on target\n",
    "        explained variance.\n",
    "        (Hint : use cumulative explained variance and target_explained_variance to find\n",
    "        top components)\n",
    "        \n",
    "        :param eig_pairs: list of tuples containing eigenvector and eigen values\n",
    "        :param var_exp: *sorted* explained variance proportions, by features\n",
    "        :return: weight matrix\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def transform_data(self, X_std, matrix_w):\n",
    "        \"\"\"\n",
    "        transform data to subspace using weight matrix\n",
    "        :param X_std: standardized data\n",
    "        :param matrix_w: weight matrix\n",
    "        :return: data in the subspace\n",
    "        \"\"\"\n",
    "        return X_std.dot(matrix_w)\n",
    "\n",
    "    def fit(self, X):\n",
    "        \"\"\"\n",
    "        entry point to the transform data to k dimensions\n",
    "        standardize and compute weight matrix to transform data.\n",
    "        :param   m X n dimension: train samples\n",
    "        :return  m X k dimension: subspace data.\n",
    "        \"\"\"\n",
    "    \n",
    "        self.feature_size = X.shape[1]\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        return self.transform_data(X_std=X_std, matrix_w=matrix_w)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bf42ca03885d2b460e78bf541d2351e4",
     "grade": false,
     "grade_id": "cell-f115fedc1c3aac43",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Part 1 [20 points]:**  Your task involves implementing helper functions to compute mean, \n",
    "covariance, eigenvector and weights.\n",
    "\n",
    "Complete `fit` to use all helper functions to find reduced dimension data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "11ba3527363fb8065febc0871d978739",
     "grade": true,
     "grade_id": "cell-1395ce0d605dc74a",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from tests import tests\n",
    "tests.run_test_suite(\"prob 1\", PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 2 [5 points]:**   Run PCA on fashion mnist dataset to reduce the dimension of the data.\n",
    "\n",
    "fashion mnist data consists of samples with 784 dimensions.\n",
    "\n",
    "Report the reduced dimension $k$ for target explained variance of **0.99**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pickle.load(open('./data/mnist/train_images.pkl','rb'))\n",
    "y_train = pickle.load(open('./data/mnist/train_image_labels.pkl','rb'))\n",
    "X_train = X_train[:15000]\n",
    "y_train = y_train[:15000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b15912907fa9d00f82d5c8e82581047b",
     "grade": true,
     "grade_id": "cell-4f2deef7b2ad8f4c",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 3 [5 points]:** Run scikit-learn SVM Classifier (refer previous homework) on the reduced dimension data with approrpiate kernel and C.\n",
    "\n",
    "Report the accuracy on test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_t, X_test, y_t, y_test = train_test_split(X_train_updated, y_train, test_size=0.2, random_state=5622)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a1e3c0aee9c27884fa3370d9620b8d50",
     "grade": true,
     "grade_id": "cell-55ac4663a6d818e1",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 4 [10 points]:** Repeat the same experiment for different values of target explained variance between: **[0.8-1.0]** with increments of $0.04$, provide the reduced dimension size for each, and then:\n",
    "\n",
    "- Plot the graph of accuracy vs target explained variance.\n",
    "- Plot the graph of the number of components vs target explained variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f0a59b38a94aa997b5a62397ce22c6da",
     "grade": true,
     "grade_id": "cell-d1c639ba61115892",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "target_explained_variances = []\n",
    "numbers_of_components = []\n",
    "accuracies = []\n",
    "for target_variance in np.arange(0.8, 1.0, .04):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "384791d90ebfef520227aebf07572b05",
     "grade": true,
     "grade_id": "cell-b3d84112a8c56eb5",
     "locked": false,
     "points": 2.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Make plots here\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discuss your observations below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5c7448f6358015c021d7af0aeb552751",
     "grade": true,
     "grade_id": "cell-ddf4e4516af2b2f2",
     "locked": false,
     "points": 2.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[20 points] Problem 2 - Statistical PCA for non-zero mean random variables. \n",
    "---\n",
    "Let $x \\in R^D$ be a random vector. Let $\\mu_x$ = $E(x)$  $ \\in R^D$ and $\\sum_x = E(x − \\mu)(x − \\mu)$ be mean an covariance of x respectivley. \n",
    "\n",
    "We define *Principal components* of $x$ as $v_i$. Assuming that the eigenvalues of $\\sum_x$ are different from each other\n",
    "\n",
    "show that\n",
    "\n",
    "1) $v_1$ is the eigenvector of $\\sum_x$ corresponding to its largest eigenvalue.\n",
    "\n",
    "2) $v_2^T v_1$ = 0 and $v_2$ is the eigenvector of $\\sum_x$ corresponding to its second largest eigenvalue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5964545d9ca55b8027aacfc1d212e96a",
     "grade": true,
     "grade_id": "cell-35f08a8505587ec1",
     "locked": false,
     "points": 20,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[40 points] Problem 3  - Decision Tree Ensembles: Bagging and Boosting\n",
    "---\n",
    "\n",
    "We are going to predict house price using decision tree ensembles.\n",
    "\n",
    "In this Regression problem, we compare Decision trees and it's ensembles - bagging and Boosting on House Price prediction dataset : https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data\n",
    "\n",
    "Make use standard Regression API's of  Decision tree ensembles from sklearn to predict the house price. http://scikit-learn.org/stable/modules/classes.html#module-sklearn.ensemble\n",
    "\n",
    "**Part 1 [20 points]:**\n",
    "Complete the `ensemble_test` class to fit appropriate model recieved as parameter and store the test accuracy.\n",
    "Later we will also use `ensemble_test` class to plot score, metric and time taken to fit the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d8156ad724afbac97b3e99faf8fe9025",
     "grade": false,
     "grade_id": "cell-2f5b11c37751fad9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "from sklearn.metrics import explained_variance_score, precision_score\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class EnsembleTest:\n",
    "    \"\"\"\n",
    "        Test multiple model performance\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, X_train, y_train, X_test, y_test, type='regression'):\n",
    "        \"\"\"\n",
    "        initialize data and type of problem\n",
    "        :param X_train:\n",
    "        :param y_train:\n",
    "        :param X_test:\n",
    "        :param y_test:\n",
    "        :param type: regression or classification\n",
    "        \"\"\"\n",
    "        self.scores = {}\n",
    "        self.execution_time = {}\n",
    "        self.metric = {}\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.type = type\n",
    "        self.score_name = 'R^2 score' if self.type == 'regression' else 'Mean accuracy score'\n",
    "        self.metric_name = 'Explained variance' if self.type == 'regression' else 'Precision'\n",
    "\n",
    "    def fit_model(self, model, name):\n",
    "        \"\"\"\n",
    "        Fit the model on train data.\n",
    "        predict on test and store score and execution time for each fit.\n",
    "        :param model: model\n",
    "        :param name: name of model\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        if self.type == 'regression':\n",
    "            self.metric[name] = explained_variance_score(predict, self.y_test)\n",
    "        elif self.type == 'classification':\n",
    "            self.metric[name] = precision_score(predict, y_test)\n",
    "\n",
    "    def print_result(self):\n",
    "        \"\"\"\n",
    "            print results for all models trained and tested.\n",
    "        \"\"\"\n",
    "        models_cross = pd.DataFrame({\n",
    "            'Model'         : list(self.metric.keys()),\n",
    "             self.score_name     : list(self.scores.values()),\n",
    "             self.metric_name    : list(self.metric.values()),\n",
    "            'Execution time': list(self.execution_time.values())})\n",
    "        print(models_cross.sort_values(by=self.score_name, ascending=False))\n",
    "\n",
    "    def plot_metric(self):\n",
    "        \"\"\"\n",
    "         plot each metric : time, metric score,scores\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = pickle.load(open('./data/house_predictions/test_train.pkl','rb'))\n",
    "\n",
    "# create a handler for ensemble_test, use the created handler for fitting different models.\n",
    "ensemble_handler = EnsembleTest(X_train,y_train,X_test,y_test,type='regression')\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "decision=DecisionTreeRegressor()\n",
    "ensemble_handler.fit_model(decision,'decision_tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 1 A [10 points]:**\n",
    "Complete the cells below to fit the dataset using `RandomForestRegressor` and `AdaBoostRegressor` with appropriate parameter. Use `n_estimators=1000` for both regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "45d3a90b9307b4c71a691414ea6a5452",
     "grade": true,
     "grade_id": "cell-8a8faea9792d3de2",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f667d8b508e624228f903db96928624e",
     "grade": true,
     "grade_id": "cell-77fc8d76bfc77a0f",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 1 B [5 points]:** Report results and make plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8de42fcf797783cc942f9289ee054777",
     "grade": true,
     "grade_id": "cell-ecde0a3f23089aaf",
     "locked": false,
     "points": 2.5,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Report results here\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bbf7cb9c1a769ac7653efe66a138cd47",
     "grade": true,
     "grade_id": "cell-2fc10988e851c39e",
     "locked": false,
     "points": 2.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Make plots here\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 2 [15 points]:** This is an extension of HW4 problem on sentiment classification over reviews.\n",
    "\n",
    "Here we make use DecisionTree ensembles to **classify** review as positive or negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews  = pd.read_csv('./data/reviews.csv')\n",
    "train, test = train_test_split(reviews, test_size=0.2, random_state=4622)\n",
    "X_train = train['reviews'].values\n",
    "X_test = test['reviews'].values\n",
    "y_train = train['sentiment']\n",
    "y_test = test['sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 2 A [10 points]:** Perform the following: \n",
    "\n",
    "* Create pipeline for `RandomForestClassifier` and `AdaBoostClassifier` as shown for `DecisionTreeClassifier` below. Refer to: http://scikit-learn.org/stable/modules/classes.html#module-sklearn.ensemble\n",
    "* Fit the reviews dataset on the above models and report the results. (tune parameters of classifier for optimal performance)\n",
    "* Use `n_estimators = 500` for both classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tokenizer and create pipeline.\n",
    "def tokenize(text): \n",
    "    tknzr = TweetTokenizer()\n",
    "    return tknzr.tokenize(text)\n",
    "en_stopwords = set(stopwords.words(\"english\")) \n",
    "vectorizer = CountVectorizer(\n",
    "    analyzer = 'word',\n",
    "    tokenizer = tokenize,\n",
    "    lowercase = True,\n",
    "    ngram_range=(1, 2),\n",
    "    stop_words = en_stopwords,\n",
    "    min_df=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a handler for ensemble_test , use the created handler for fitting different models.\n",
    "ensemble_classifier_handler = EnsembleTest(X_train,y_train,X_test,y_test,type='classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "pipeline_decision_tree = make_pipeline(vectorizer, DecisionTreeClassifier())\n",
    "ensemble_classifier_handler.fit_model(pipeline_decision_tree,'decision tree classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_classifier_handler.print_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "36bfba82604c3aef47f990ead5202ab3",
     "grade": true,
     "grade_id": "cell-5ba823d25c616289",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c1db4b5c2b0ca06fdc563f968143a202",
     "grade": true,
     "grade_id": "cell-0921e901522a923e",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 2 B [5 points]:** Report results and make plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f0b991c14cb2d605bac8f5fd8310b065",
     "grade": true,
     "grade_id": "cell-c19776c62148ed3f",
     "locked": false,
     "points": 2.5,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Report results here\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "305ac6686c2cac2f4c01d5249297b590",
     "grade": true,
     "grade_id": "cell-daca4a565756ec40",
     "locked": false,
     "points": 2.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Make plots here\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Part 3 [10 points]:** In the following space below discuss at least one advantage and disadvantage for *Random Forest* and *AdaBoost*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2593940b46e846297e4ec5f1bec3e768",
     "grade": true,
     "grade_id": "cell-15ec51992550c8fc",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Optional survey.\n",
    "***\n",
    "\n",
    "We are always interested in your feedback. At the end of each homework, there is a simple anonymous feedback [survey](https://forms.gle/T9VKL7UPWjWoYxVu6) to solicit your feedback for how to improve the course."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
