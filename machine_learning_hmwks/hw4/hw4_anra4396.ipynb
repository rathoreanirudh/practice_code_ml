{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4: SVM\n",
    "\n",
    "\n",
    "This assignment is due on Moodle by **11:59pm on Friday November 8**. \n",
    "Your solutions to theoretical questions should be done in Markdown/MathJax directly below the associated question.\n",
    "Your solutions to computational questions should include any specified Python code and results \n",
    "as well as written commentary on your conclusions.\n",
    "Remember that you are encouraged to discuss the problems with your instructors and classmates, \n",
    "but **you must write all code and solutions on your own**. For a refresher on the course **Collaboration Policy** click [here](https://github.com/BoulderDS/CSCI5622-Machine-Learning/blob/master/info/syllabus.md#collaboration-policy).\n",
    "\n",
    "**NOTES**: \n",
    "\n",
    "- Do **NOT** load or use any Python packages that are not available in Anaconda (Version: 2019.07) with Python 3.7. \n",
    "- Some problems with code may be autograded.  If we provide a function API **do not** change it.  If we do not provide a function API then you're free to structure your code however you like. \n",
    "- Submit only this Jupyter notebook to Moodle.  Do not compress it using tar, rar, zip, etc. \n",
    "- In this homework you will explore the primal and dual representations of support vector machines, as well as the performance of various kernels while classifying sentiments. Install the following packages: `nltk` (Version: 3.4.5), `scikit-learn` (Version: 0.21.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Anirudh Rathore\n",
    "\n",
    "identikey: anra4396"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pickle\n",
    "import gzip\n",
    "import numpy as np\n",
    "import pandas\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[40 Points] Problem 1 - Basic concepts of SVM\n",
    "---\n",
    "\n",
    "**Part 1 [10 points]:** \n",
    "* What are the main differences between the primal and the dual representations?\n",
    "* For the variables $\\xi_i$, $C$ in the primal formation, what are their roles? Write out the upper/lower bounds (constraints) of these variables. What are the interpretation for these maximum/minimum values?\n",
    "* For the variable $\\alpha_i$, $\\beta_i$ in the dual formation, what are the upper/lower bound (constraints) of them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f616bf5ea6cd25ba5b9bbbf94bb465f5",
     "grade": true,
     "grade_id": "cell-f177349aed9aabcf",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "* The primal representation is $$\\frac{1}{2}\\min_{w, b, \\xi} ||w^2 || + C\\sum_{i=1}^m\\xi_i$$ such that $$y_i(w.x_i + b) \\geq 1 - \\xi_i, i\\in[1, m]$$ $$\\xi_i \\geq 0, i\\in[1, m]$$ This can be re-written using langragian multiplier $$\\mathscr{L}(w, b, \\xi, \\alpha, \\beta) = \\frac{1}{2}\\min_{w, b, \\xi} ||w^2 || + C\\sum_{i=1}^n\\xi_i - \\sum_{i=1}^m\\alpha_i[y_i(w.x_i + b) - 1 + \\xi_i] - \\sum_{i=1}^m\\beta_i\\xi_i$$\n",
    "\n",
    "Taking the gradients($\\triangledown_w\\mathscr{L}$, $\\triangledown_b\\mathscr{L}$, $\\triangledown_{\\xi_i}\\mathscr{L}$) and solving for zero gives us the following equations $w = \\sum_{i=1}^m\\alpha_iy_ix_i$, $\\sum_{i=1}^m\\alpha_iy_i = 0$, $\\alpha_i + \\beta_i = C$\n",
    "\n",
    "which gives us the dual representations. The key point in this is that dual representations is max-min compared to the min-max in primal. The primal problem also suffers the curse of dimensionality and cannot be solved efficiently, whereas when the number of support vectors are not unlimited, the dual problem can be solved very efficiently.\n",
    "\n",
    "* The variables $\\xi_i, C$ are the slack variable and the tradeoff between slack and margin respectively. The role of $\\xi_i$ is to check how wrong a point is classified in the case of soft margin SVM. The role of C is to dictate how much slack can we live with in our classifier. If the value of C is high, this means that we cannot have a lot of slack in our classifier and it tends towards a hard margin SVM, whereas if the vakue of C is low, this means that we can concentrate on maximizing the margin and allow slack for a couple of points. $$\\xi_i \\geq 0, i\\in[1, m]$$ $$C\\geq \\alpha_i \\geq 0, i\\in[1, m]$$\n",
    "\n",
    "If the value of $\\xi_i$ is zero for a point, that means that the point is not misclassifed but if the value of slack is higher than zero, then it is the degree of how wrong a point is classified, i.e, how far is it from the decision boundary.\n",
    "* $$\\alpha_i \\geq 0, i\\in[1, m]$$\n",
    "$$\\beta_i \\geq 0, i\\in[1, m]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 2 [20 points]:** \n",
    "\n",
    " * Given a weight vector, implement the `find_support` function that returns the indices of the support vectors.\n",
    " * Given a weight vector, implement the `find_slack` function that returns the indices of the vectors with nonzero slack.\n",
    " * Given the alpha dual vector, implement the `weight_vector` function that returns the corresponding weight vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "95c07ce92336485501945c905ee57cdd",
     "grade": false,
     "grade_id": "cell-14c104d96c00c2eb",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "class SVM:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.kINSP = np.array([(1, 8, +1),\n",
    "                       (7, 2, -1),\n",
    "                       (6, -1, -1),\n",
    "                       (-5, 0, +1),\n",
    "                       (-5, 1, -1),\n",
    "                       (-5, 2, +1),\n",
    "                       (6, 3, +1),\n",
    "                       (6, 1, -1),\n",
    "                       (5, 2, -1)])\n",
    "        self.kSEP = np.array([(-2, 2, +1),    # 0 - A\n",
    "                      (0, 4, +1),             # 1 - B\n",
    "                      (2, 1, +1),             # 2 - C\n",
    "                      (-2, -3, -1),           # 3 - D\n",
    "                      (0, -1, -1),            # 4 - E\n",
    "                      (2, -3, -1),            # 5 - F\n",
    "                      ])\n",
    "\n",
    "\n",
    "    def weight_vector(self, x, y, alpha):\n",
    "        \"\"\"\n",
    "        Given a vector of alphas, compute the primal weight vector w.\n",
    "        The vector w should be returned as an Numpy array.\n",
    "        \"\"\"\n",
    "\n",
    "        w = np.zeros(len(x[0]))\n",
    "        # YOUR CODE HERE\n",
    "        # BEGIN CODE HERE\n",
    "        for i in range(len(x)):\n",
    "            wt_feature =  []\n",
    "            for j in range(len(x[i])):\n",
    "                tmp = x[i][j]*y[i]*alpha[i]\n",
    "                wt_feature.append(tmp)\n",
    "            wt_feature = np.array(wt_feature)\n",
    "            w = np.add(w, wt_feature)\n",
    "        # END CODE HERE\n",
    "        return w\n",
    "\n",
    "\n",
    "\n",
    "    def find_support(self, x, y, w, b, tolerance=0.001):\n",
    "        \"\"\"\n",
    "        Given a set of training examples and primal weights, return the indices\n",
    "        of all of the support vectors as a set.\n",
    "        \"\"\"\n",
    "\n",
    "        support = set()\n",
    "        # YOUR CODE HERE\n",
    "        # BEGIN CODE HERE\n",
    "        y_hat = np.dot(x, w) + b\n",
    "        for i in range(len(x)):\n",
    "            xx = int(y_hat[i]*y[i])\n",
    "            if xx == 1:\n",
    "                support.add(i)\n",
    "            \n",
    "        # END CODE HERE\n",
    "        \n",
    "        return support\n",
    "\n",
    "\n",
    "\n",
    "    def find_slack(self, x, y, w, b):\n",
    "        \"\"\"\n",
    "        Given a set of training examples and primal weights, return the indices\n",
    "        of all examples with nonzero slack as a set.\n",
    "        \"\"\"\n",
    "\n",
    "        slack = set()\n",
    "        # YOUR CODE HERE\n",
    "        # BEGIN CODE HERE\n",
    "        y_hat = np.dot(x, w) + b\n",
    "        for i in range(len(x)):\n",
    "            xx = y_hat[i]*y[i]\n",
    "            if xx < 1:\n",
    "                slack.add(i)\n",
    "        # END CODE HERE\n",
    "        return slack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3aa73cc220bc2b16c09b0e72ebd10dfa",
     "grade": true,
     "grade_id": "cell-3c7d7f432578009e",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TestWideSlack (tests.tests.TestSVM) ... ok\n",
      "TestNarrowSlack (tests.tests.TestSVM) ... ok\n",
      "TestSupport (tests.tests.TestSVM) ... ok\n",
      "TestWeight (tests.tests.TestSVM) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.006s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "from tests import tests\n",
    "tests.run_test_suite(\"prob 1\", SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 3 [10 points]:** \n",
    "\n",
    "The goal of this problem is to correctly classify test data points, given a training data set.\n",
    "For this problem, assume that we are training an SVM with a quadratic kernel, which means our kernel function is a polynomial kernel of degree 2. You are given the data set presented in the figure below. The slack penalty $C$ will determine the location of the decision boundary.\n",
    "\n",
    "Justify the following questions in a sentence or via drawing decision boundary.\n",
    "![training_data](./data/data.png)\n",
    "\n",
    "* Where would the decision boundary be for very large values of $C$ ?\n",
    "* Where you would expect the decision boundary to be if  $C = 0$ ?\n",
    "* Which of the two cases above would you expect to generalize better on test data? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "985db05b9496fb3714ee2096479f6f7d",
     "grade": true,
     "grade_id": "cell-02406ba497be1623",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "\n",
    "* The decision boundary for very large values of C will be where it tries to classify all the points correctly. This means that it would try to have a clear demarcation between the two classes. Because as C increases, the slack penalty increases, so for the two red points which we see are closer to the green cluster would have lesser and lesser slack when thje value of C increases and hence, they would play an important role in the decision boundary.\n",
    "\n",
    "* For C=0, the decision boundary would be focused on maximizing the margin and would live with a couple of misclassifications. So, it would be kindof in the middle of the big clusters of data.\n",
    "\n",
    "* I would expect that the C=0 case would generalize better on the test data because when C is larger, it's worried about the misclassifications and would probably overfit on the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[30 points] Problem 2 - The Kernel Trick\n",
    "---\n",
    "The kernel trick can make SVM powerful and become non-linear. In this problem we will get familiar with the kernel trick.\n",
    "\n",
    "**Part 1 [10 points]:**\n",
    "\n",
    "We will construct a support vector machine that computes the XOR function, using values of +1 and −1 (instead of 1 and 0) for both inputs and outputs, so that an example looks like ($[−1, 1], 1$) or ($[−1, −1], −1$). Map the input $[x_1, x_2]$ into a space consisting of $x_1$ and $x_1x_2$. Plot the four input points in this space, and the maximal margin separator. Give the margin value in the markdown cell. Remeber to indicate which points have output +1 and which -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e495557a163be3eb33fccc9d445e8de3",
     "grade": false,
     "grade_id": "cell-20ea52b04bb94dee",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'x1x2')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA38AAAF4CAYAAADkLUAeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3de3RV9Z338c83pCGmihKIXMJVgYQAAnIGWmnHekEtnYp91Cn1Ak7loehoFaej9nFKfdLxaW1XR9uOLWIHqsVRW6xLrDgWFbVrWapBQC6KogW5BAkiKOVOvs8fZ8cewklyYs4t+b1fa511zv7t3977e37uHM+HfTnm7gIAAAAAdGwFuS4AAAAAAJB5hD8AAAAACADhDwAAAAACQPgDAAAAgAAQ/gAAAAAgAIQ/AAAAAAhAYa4LyLXu3bv7gAEDcl0GAAAAOrBly5btcPeyXNeBsAUf/gYMGKCamppclwEAAIAOzMw25roGgNM+AQAAACAAhD8AAAAACADhDwAAAAACQPgDAAAAgAAQ/gAAAAAgAIQ/AAAAAAgA4Q8AAAAAAkD4AwAAAIAAEP4AAAAAIACEPwAAAAAIQN6FPzOba2bbzWx1E/PNzH5qZuvN7DUzOz1h3lQzeyt6TM1e1QAAAACQ3/Iu/En6laQLmpn/RUmDo8d0Sb+QJDMrlfRdSeMkjZX0XTPrmtFK2+rBB6UBA6SCgvjzgw/muiIAAICOg+9awFEKc11AY+7+opkNaKbLJEkPuLtLWmpmJ5lZL0lfkLTY3XdKkpktVjxEPpTZij+hBx+Upk+X9u6NT2/cGJ+WpMsvz11dAAAAHQHftYBj5OORv5aUS9qUML05amuqPT/ddtvfPowa7N0bbwcAAEDb8F0LOEZ7DH+WpM2baT92BWbTzazGzGrq6urSWlzK3n23de0AAABIHd+1gGO0x/C3WVLfhOk+krY2034Md5/j7jF3j5WVlWWs0Gb169e6dgAAAKSO71rAMdpj+FsoaUp018/PSNrt7rWSnpZ0npl1jW70cl7Ulp/uuEMqKTm6raQk3g4AAIC24bsWcIy8u+GLmT2k+M1bupvZZsXv4PkpSXL32ZIWSZooab2kvZL+KZq308y+J+mVaFXVDTd/yUsNFxrfdlv89IN+/eIfRlyADAAA0HZ81wKOYfGbZoYrFot5TU1NrssAAABAB2Zmy9w9lus6ELb2eNonAAAAAKCVCH8AAAAAEADCHwAAAAAEgPAHAAAAAAEg/AEAAABAAAh/AAAAABAAwh8AAAAABIDwBwAAAAABIPwBAAAAQAAIfwAAAAAQAMIfAAAAAASA8AcAAAAAASD8AQAAAEAACH8AAAAAEADCHwAAAAAEgPAHAAAAAAEg/AEAAABAAAh/AAAAABAAwh8AAAAABIDwBwAAAAABIPwBAAAAQAAIfwAAAAAQAMIfAAAAAASA8AcAAAAAASD8AQAAAEAACH8AAAAAEADCHwAAAAAEgPAHAAAAAAHIu/BnZheY2TozW29mtyaZf5eZrYgeb5rZroR5RxLmLcxu5QAAAACQvwpzXUAiM+sk6R5JEyRtlvSKmS1097UNfdx9ZkL/6yWNTljFPncfla16AQAAAKC9yLcjf2MlrXf3d9z9oKSHJU1qpv/XJD2UlcoAAAAAoB3Lt/BXLmlTwvTmqO0YZtZf0kBJzyU0F5tZjZktNbOLmtqImU2P+tXU1dWlo24AAAAAyGv5Fv4sSZs30XeypAXufiShrZ+7xyRdJuluMzs12YLuPsfdY+4eKysra1vFAAAAANAO5Fv42yypb8J0H0lbm+g7WY1O+XT3rdHzO5Ke19HXAwIAAABAsPIt/L0iabCZDTSzIsUD3jF37TSzCkldJf0poa2rmXWOXneXNF7S2sbLAgAAAECI8upun+5+2Myuk/S0pE6S5rr7GjOrllTj7g1B8GuSHnb3xFNCh0q618zqFQ+1P0i8SygAAAAAhMyOzk/hicViXlNTk+syAAAA0IGZ2bLo3hRAzuTbaZ8AAAAAgAwg/AEAAABAAAh/AAAAABAAwh8AAAAABIDwBwAAAAABIPwBAAAAQAAIfwAAAAAQAMIfAAAAAASA8AcAAAAAASD8AQAAAEAACH8AAAAAEADCHwAAAAAEgPAHAAAAAAEg/AEAAABAAAh/AAAAABAAwh8AAAAABIDwBwAAAAABIPwBAAAAQAAIfwAAAAAQAMIfAAAAAASA8AcAAAAAASD8AQAAAEAACH8AAAAAEADCHwAAAAAEgPAHAAAAAAEg/AEAAABAAAh/AAAAABCAvAt/ZnaBma0zs/VmdmuS+VeZWZ2ZrYge0xLmTTWzt6LH1OxWDgAAAAD5qzDXBSQys06S7pE0QdJmSa+Y2UJ3X9uo6yPufl2jZUslfVdSTJJLWhYt+0EWSgcAAACAvJZvR/7GSlrv7u+4+0FJD0ualOKy50ta7O47o8C3WNIFGaoTAAAAANqVfAt/5ZI2JUxvjtoau9jMXjOzBWbWt5XLAgAAAEBw8i38WZI2bzT9hKQB7n6apGck3d+KZeMdzaabWY2Z1dTV1X3iYgEAAACgvci38LdZUt+E6T6StiZ2cPf33f1ANHmfpDGpLpuwjjnuHnP3WFlZWVoKBwAAAIB8lm/h7xVJg81soJkVSZosaWFiBzPrlTB5oaTXo9dPSzrPzLqaWVdJ50VtAAAAABC8vLrbp7sfNrPrFA9tnSTNdfc1ZlYtqcbdF0r6ppldKOmwpJ2SroqW3Wlm31M8QEpStbvvzPqbAAAAAIA8ZO5JL4sLRiwW85qamlyXAQAAgA7MzJa5eyzXdSBs+XbaJwAAAAAgAwh/AAAAABAAwh8AAAAABIDwBwAAAAABIPwBAAAAQAAIfwAAAAAQAMIfAAAAAASA8AcAAAAAASD8AQAAAEAACH8AAAAAEADCHwAAAAAEgPAHAAAAAAEg/AEAAABAAAh/AAAAABAAwh8AAAAABIDwBwAAAAABIPwBAAAAQAAIfwAAAAAQAMIfAAAAAASA8AcAAAAAASD8AQAAAEAACH8AAAAAEADCHwAAAAAEgPAHAAAAAAEg/AEAAABAAAh/AAAAABAAwh8AAAAABIDwBwAAAAAByLvwZ2YXmNk6M1tvZrcmmX+Tma01s9fM7Fkz658w74iZrYgeC7NbOQAAAADkr8JcF5DIzDpJukfSBEmbJb1iZgvdfW1Ct+WSYu6+18yukfRDSV+N5u1z91FZLRoAAAAA2oF8O/I3VtJ6d3/H3Q9KeljSpMQO7r7E3fdGk0sl9clyjQAAAADQ7uRb+CuXtClhenPU1pSrJT2VMF1sZjVmttTMLmpqITObHvWrqaura1vFAAAAANAO5NVpn5IsSZsn7Wh2haSYpDMTmvu5+1YzO0XSc2a2yt3fPmaF7nMkzZGkWCyWdP0AAAAA0JHk25G/zZL6Jkz3kbS1cSczO1fSbZIudPcDDe3uvjV6fkfS85JGZ7JYAAAAAGgv8i38vSJpsJkNNLMiSZMlHXXXTjMbLelexYPf9oT2rmbWOXrdXdJ4SYk3igEAAACAYOXVaZ/uftjMrpP0tKROkua6+xozq5ZU4+4LJf1I0vGSfmtmkvSuu18oaaike82sXvFQ+4NGdwkFAAAAgGCZe9iXvMViMa+pqcl1GQAAAOjAzGyZu8dyXQfClm+nfQIAAAAAMoDwBwAAAAABIPwBAAAAQAAIfwAAAAAQAMIfAAAAAASA8AcAAAAAASD8AQAAAEAACH8AAAAAEADCHwAAAAAEgPAHAAAAAAEg/AEAAABAAAh/AAAAABAAwh8AAAAABIDwBwAAAAABIPwBAAAAQAAIfwAAAAAQgBbDn5mVm9ntZnafmc00sxOT9BlqZs9lpkQAAAAAQFsVNjfTzAZIqpHUVVKdpKsl3WJml7v7swldu0g6M0M1AgAAAADaqKUjf/8uabukge7eU9IwSeskLTKzyzJdHAAAAAAgPVoKf5+XVO3u70qSu78u6WxJ8yQ9YGbXZrg+AAAAAEAaNHvap6TukrYkNrj7EUkzzOwDST8zsxMkPZ+Z8gAAAAAA6dBS+HtX8VM9/9h4hrt/28z2SPq+pKcyUBsAAAAAIE1aOu3zRUmXNzXT3e+QdKOkC9JZFAAAAAAgvVo68jdH0mQz6+bu7yfr4O4/NbPtks5Pe3UAAAAAgLRoNvy5+zJJy1paibs/LOnhdBUFAAAAAEivFn/kvYGZjWxh/qVtLwcAAAAAkAkphz9JfzazGxo3mlmJmc0VR/4AAAAAIG+1Jvz9h6Qfm9mTZlYmSWZ2uqRXJV0saUo6CjKzC8xsnZmtN7Nbk8zvbGaPRPP/bGYDEuZ9O2pfZ2ZcgwgAAAAAkZTDn7v/H0kTJI2U9JqZ/YeklyTtkjTa3R9sazFm1knSPZK+KKlK0tfMrKpRt6slfeDugyTdJenOaNkqSZMV/2mKCyT9PFofAAAAAASvNUf+5O5LJJ0n6SRJN0haKWm8u7+TpnrGSlrv7u+4+0HFTyWd1KjPJEn3R68XSDrHzCxqf9jdD7j7XyStj9YHAAAAAMFr6acejhKdSvkrSTskPSnpf0v6nZl9vamfgmilckmbEqY3SxrXVB93P2xmuyV1i9qXNlq2PA01ZdSNN96oFStW5LoMAACADmvUqFG6++67c10GkHOtudvnjyUtUjxgjXT3GYr/tl9M8dNAz05DPZakzVPsk8qy8RWYTTezGjOrqaura2WJAAAAAND+tObI3zWSrnP3XzQ0uPszZnaapHmS/tDK9SWzWVLfhOk+krY20WezmRVKOlHSzhSXbah7juI/YK9YLJY0IGYL/woFAAAAIBtac83f3yUGvwbu/r67X6j4NYBt9YqkwWY20MyKFL+By8JGfRZKmhq9vkTSc+7uUfvk6G6gAyUNlvRyGmoCAAAAgHYv5SN17r6mhfn3tLWY6Bq+6yQ9LamTpLnuvsbMqiXVuPtCSf8l6ddmtl7xI36TG+ozs99IWivpsKR/dvcjba0JAAAAADoCix80a+NKzLpLqnL3F9teUnbFYjGvqanJdRkAAADowMxsmbvHcl0Hwtaqn3poxpmSlqRpXQAAAACANEtX+AMAAAAA5LFmr/kzs7kprqd/GmoBAAAAAGRISzd8uUrSbkl7Wuh3XFqqAQAAAABkREvh711Jf3D36c11MrNLJD2StqoAAAAAAGnV0jV/NZJSuStRTn8oHQAAAADQvJbC30JJO1JYz1pJ1W0vBwAAAACQCc2GP3d/wN3Pa2kl7v66u//f9JUFAAAAAEinlH/qwcyuaWZeZzO7Jz0lAQAAAADSrTW/8/efZvaYmZUmNprZcEnLJE1Ja2UAAAAAgLRpTfj7oqTPSFppZl+QJDP7pqSXJR2QNCbt1QEAAAAA0iLl8Ofuf5A0UtIaSc+Y2TJJ/yHpF5I+4+5vZqZEAAAAAEBbtebIn9x9u6QfSTokabSk5ZK+5+6HMlAbAAAAACBNWnPDl05m9v8kPS3pOUmXSeoraYWZfS5D9QEAAAAA0qA1R/5eknSTpG+5+5fc/WFJoyStk7TEzPipBwAAAADIU60Jf10Uv7bv7oYGd9/m7udLulXSzekuDgAAAACQHoWt6DvG3fcmm+HuPzazZ9NUEwAAAAAgzVpzt8+kwS9h/oq2lwMAAAAAyIRW3e0TAAAAANA+Ef4AAAAAIACEPwAAAAAIAOEPAAAAAAJA+AMAAACAABD+AAAAACAAhD8AAAAACADhDwAAAAACQPgDAAAAgAAQ/gAAAAAgAHkT/sys1MwWm9lb0XPXJH1GmdmfzGyNmb1mZl9NmPcrM/uLma2IHqOy+w4AAAAAIH/lTfiTdKukZ919sKRno+nG9kqa4u7DJF0g6W4zOylh/r+6+6josSLzJQMAAABA+5BP4W+SpPuj1/dLuqhxB3d/093fil5vlbRdUlnWKgQAAACAdiqfwl8Pd6+VpOj55OY6m9lYSUWS3k5oviM6HfQuM+vczLLTzazGzGrq6urSUTsAAAAA5LWshj8ze8bMVid5TGrlenpJ+rWkf3L3+qj525IqJf2dpFJJtzS1vLvPcfeYu8fKyjhwCAAAAKDjK8zmxtz93Kbmmdl7ZtbL3WujcLe9iX5dJD0p6d/cfWnCumujlwfMbJ6kb6WxdAAAAABo1/LptM+FkqZGr6dKerxxBzMrkvSYpAfc/beN5vWKnk3x6wVXZ7RaAAAAAGhH8in8/UDSBDN7S9KEaFpmFjOzX0Z9/lHS30u6KslPOjxoZqskrZLUXdK/Z7d8AAAAAMhf5u65riGnYrGY19TU5LoMAAAAdGBmtszdY7muA2HLpyN/AAAAAIAMIfwBAAAAQAAIfwAAAAAQAMIfAAAAAASA8AcAAAAAASD8AQAAAEAACH8AAAAAEADCHwAAAAAEgPAHAAAAAAEg/AEAAABAAAh/AAAAABAAwh8AAAAABIDwBwAAAAABIPwBAAAAQAAIfwAAAAAQAMIfAAAAAASA8AcAAAAAASD8AQAAAEAACH8AAAAAEADCHwAAAAAEgPAHAAAAAAEg/AEAAABAAAh/AAAAABAAwh8AAAAABIDwBwAAAAABIPwBAAAAQAAIfwAAAAAQAMIfAAAAAAQgb8KfmZWa2WIzeyt67tpEvyNmtiJ6LExoH2hmf46Wf8TMirJXPQAAAADkt7wJf5JulfSsuw+W9Gw0ncw+dx8VPS5MaL9T0l3R8h9Iujqz5QIAAABA+5FP4W+SpPuj1/dLuijVBc3MJJ0tacEnWR4AAAAAOrp8Cn893L1WkqLnk5voV2xmNWa21MwaAl43Sbvc/XA0vVlSeVMbMrPp0Tpq6urq0lU/AAAAAOStwmxuzMyekdQzyazbWrGafu6+1cxOkfScma2S9GGSft7UCtx9jqQ5khSLxZrsBwAAAAAdRVbDn7uf29Q8M3vPzHq5e62Z9ZK0vYl1bI2e3zGz5yWNlvSopJPMrDA6+tdH0ta0vwEAAAAAaKfy6bTPhZKmRq+nSnq8cQcz62pmnaPX3SWNl7TW3V3SEkmXNLc8AAAAAIQqn8LfDyRNMLO3JE2IpmVmMTP7ZdRnqKQaM1upeNj7gbuvjebdIukmM1uv+DWA/5XV6gEAAAAgj1n8oFm4YrGY19TU5LoMAAAAdGBmtszdY7muA2HLpyN/AAAAAIAMIfwBAAAAQAAIfwAAAAAQAMIfAAAAAASA8AcAAAAAASD8AQAAAEAACH8AAAAAEIDCXBcAAAAAIH2WLVt2cmFh4S8lDRcHe0JSL2n14cOHp40ZM2Z7sg6EPwAAAKADKSws/GXPnj2HlpWVfVBQUOC5rgfZUV9fb3V1dVXbtm37paQLk/XhXwIAAACAjmV4WVnZhwS/sBQUFHhZWdluxY/4Ju+TxXoAAAAAZF4BwS9M0X/3JjMe4Q8AAABAxtx00029Z82a1eOTLDt69OjK5uafeeaZg3bs2NHpk1X2NxdffPGAefPmdW3relqjpKRkdDa3J3HNHwAAAIA8tXz58jeam//CCy+sz1YtuVRfXy93V6dObcu5HPkDAAAAkFa33HJLzwEDBgw/44wzhrz11ludG9rXrFnT+fOf//zgYcOGDR0zZkzF8uXLiyVp06ZNhRMmTDi1oqKiqqKiomrx4sWflv52dGzjxo2fisViFZWVlVWDBw8e9j//8z/HS1J5efmI2traQkm6/fbbewwePHjY4MGDh1VXV58sSevWrSs65ZRThk2ePLn/oEGDho0fP37wnj17LFnNixcvPmHMmDEVAwYMGP7QQw+dKEl79+61Sy65ZMCQIUOqhg4dWvXEE0+cIEk//elPu02ZMqVfw7JnnXXWoN///vcnNNR8/fXXl1dUVFSNHDmyctOmTYWS9MYbbxSNGjWqcvjw4UNvuOGG3g3L7t69u+Czn/3skKqqqqFDhgypmj9//kmJtV9xxRX9hg0bVnXzzTf3uvrqq/s2LPfjH/+4+7Rp0/q05r8LR/4AAACADurrX/9639WrV5ekc53Dhw/fO3fu3E1Nzf/jH/9Y8thjj5WuWrVq7aFDhzRq1Kiq0aNH75WkadOm9Z8zZ87GESNGHHjuuec+fc011/RbunTpmzNmzOj3+c9//qNZs2a9ffjwYe3evfuoQ1xz584tPeecc3bfeeed2w4fPqyPPvqooPE2//u//7vbsmXLXnd3jRkzZug555zzUffu3Y+8++67xfPnz3/njDPO2Dhx4sRTHnjgga7XXnvtzsZ1b9q0qfPLL7+8bu3atZ3PPffcikmTJq268847T5akN998c+3y5cuLJ06cOPjtt99e3dz47Nu3r+Czn/3snp/97GdbZsyY0ednP/tZ2Q9/+MPaa6+9tt+0adPqrrvuuve///3vlzX0LykpqX/yySfXl5aW1tfW1haOGzeu8rLLLtslSRs2bCi+7777NsyfP//dDz/8sGDYsGFVBw4c2Ny5c2efP39+93vvvXdjKv/NGhD+AAAAAKTNkiVLjp84ceKuE044oV6SzjvvvF1S/AjX8uXLj7/00ktPbeh78OBBk6SXXnrphAULFvxFkgoLC9WtW7cjiev8zGc+89dvfOMbAw4dOlRwySWXfHDGGWfsS5z//PPPHz9x4sRdXbp0qZekL33pSx8sWbLkhEsvvXRXeXn5gYb+o0eP3rthw4bOSuLiiy/e2alTJ40YMeJA3759D6xYsaL4pZdeOv7666/fHi27v3fv3gdXrVpV3Nz7/9SnPuWTJ0/eLUljxoz56zPPPNNFkl599dXjn3rqqbcl6Rvf+Mb73/ve9/pI8Z9ouPHGG/ssXbr0+IKCAm3fvr1o8+bNhZLUq1evg+ecc85fJalLly7148eP/+iRRx45ccSIEfsPHTpkY8eO3Ze8iuQIfwAAAEAH1dwRukwyO/bMyiNHjuiEE044/MYbb6xt7fq++MUv7nnxxRfXPfrooydeddVVA7/5zW++d911173fMN+96ZubFhUVfTyzU6dOvm/fvqSXvjWu2cyaXG9hYaHX19d/PH3gwIGCxHkFBQUNr3X48OGPV5zsLqz33ntv6fvvv1+4atWq1zt37uzl5eUjGmosKSmpT+w7ffr0HXfccUfPIUOG7L/iiit2NPmmm8A1fwAAAADS5uyzz97z5JNPnrRnzx774IMPChYvXnySJJWWltb36dPn4Ny5c7tK8ZuY/OlPfzpOksaPH//Rj370ozJJOnz4sHbu3HlUTnnzzTeLysvLD/3Lv/zLjiuuuGLHq6++WtJ4m4sWLTrpo48+Kvjwww8LFi1a1PWss876qDV1/+53v+t65MgRrVmzpvOmTZs6jxw5cv/nPve5PfPnzy+VpNdee61zbW1t0Wmnnbb/1FNPPbhmzZqSI0eOaP369Z967bXXPt3S+k8//fQ99913X6kk3Xfffd0a2nfv3t2pe/fuhzp37uxPPPHECVu3bi1qah1nn332X2tra4see+yxbldfffUxp662hPAHAAAAIG0+97nP7f3KV76yc/jw4cP+4R/+4dSxY8fuaZj30EMPvTNv3rzuFRUVVYMHDx726KOPniRJv/jFL9594YUXThgyZEjV8OHDq1599dXjEtf59NNPn1BVVTVs6NChVY8//njXm2+++b3G27zsssveP/3004eOGTNm6JVXXlk3fvz4Vp0SOWjQoANjx46t+NKXvjT47rvv3lhSUuI333zz9iNHjtiQIUOqvvrVr5567733bjjuuON8woQJe/r27XugoqJi2A033NC3qqpqb0vr//nPf/7unDlzTh4+fPjQxGsap02btnPlypWfHj58+ND58+eXDhw4cH9z67nooos+iMVie8rKyo401y8Za+4QaQhisZjX1NTkugwAAAB0YGa2zN1j2djWypUrN4wcObLVpwSifTjrrLMG3Xjjje9NmjQp6ZHNlStXdh85cuSAZPM48gcAAAAAeW7Hjh2dBgwYMLy4uLi+qeDXEm74AgAAAAB5rnv37kc2bNjQ7M9MtIQjfwAAAAAQAMIfAAAAAASA8AcAAAAAASD8AQAAAEAACH8AAAAAsmLbtm2dxo0bN6SkpGT0lClT+uW6ntDkTfgzs1IzW2xmb0XPXZP0OcvMViQ89pvZRdG8X5nZXxLmjcr+uwAAAADQlJKSEq+urt56++23b851LSHKm/An6VZJz7r7YEnPRtNHcfcl7j7K3UdJOlvSXkl/SOjyrw3z3X1FVqoGAAAA2rPZs0vVu/cIFRSMUe/eIzR7dmmmNtWlS5f6888/f09xcXF9praBpuVT+Jsk6f7o9f2SLmqh/yWSnnL3vRmtCgAAAOioZs8u1cyZ/VVbWyR3qba2SDNn9s9kAETu5FP46+HutZIUPZ/cQv/Jkh5q1HaHmb1mZneZWeemFjSz6WZWY2Y1dXV1basaAAAAaK+qq8u1f//RmWD//gJVV5fnqCJkUFbDn5k9Y2arkzwmtXI9vSSNkPR0QvO3JVVK+jtJpZJuaWp5d5/j7jF3j5WVlX2CdwIAAAB0ANu2FbWqvZUeeOCBkyorK6sqKyurXnzxxZJ0rBOfXGE2N+bu5zY1z8zeM7Ne7l4bhbvtzazqHyU95u6HEtZdG708YGbzJH0rLUUDAAAAHVXPngdVW3ts0OvZ82A6Vj9lypRdU6ZM2ZWOdaHt8um0z4WSpkavp0p6vJm+X1OjUz6jwCgzM8WvF1ydgRoBAACAjmPWrC1qfPOV4uJ6zZq1JVObLC8vH/Gd73yn74IFC7r16NHjtGXLlhVnals4WlaP/LXgB5J+Y2ZXS3pX0qWSZGYxSTPcfVo0PUBSX0kvNFr+QTMrk2SSVkiakZ2yAQAAgHZqxoydkuLX/m3bVqSePQ9q1qwtH7dnwJYtW1Zlat1oXt6EP3d/X9I5SdprJE1LmN4g6ZgLUN397EzWBwAAAHRIM2bszGTYQ/7Ip9M+AQAAAAAZQvgDAAAAgAAQ/gAAAAAgAIQ/AAAAAAgA4Q8AAAAAAkD4AwAAAJAV27Zt6zRu3LghJSUlo6dMmdIv1/WEJm9+6gEAAABAx1ZSUuLV1dVbV65cedzq1auPy3U9oeHIHwAAABCy2bNL1bv3CBUUjFHv3iM0e3ZppjbVpUuX+vPPP39PcdALknkAAA8+SURBVHFxfaa2gaZx5A8AAAAI1ezZpZo5s7/2748fFKqtLdLMmf0liR9+73g48gcAAACEqrq6/OPg12D//gJVV5fnqCJkEOEPAAAACNW2bUWtam+lBx544KTKysqqysrKqhdffLEkHevEJ8dpnwAAAECoevY8qNraY4Nez54H07H6KVOm7JoyZcqudKwLbceRPwAAACBUs2ZtUeObrxQX12vWrC2Z2mR5efmI73znO30XLFjQrUePHqctW7asOFPbwtE48gcAAACEquGmLtXV5dq2rUg9ex7UrFlbMnmzly1btqzK1LrRPMIfAAAAELIZM3ZyZ88wcNonAAAAAASA8AcAAAAAASD8AQAAAEAACH8AAAAAEADCHwAAAAAEgPAHAAAAIGeeeuqp46uqqoYWFhaOmTdvXtdc19OREf4AAAAAZNy6deuKxo4dW9G4/ZRTTjk4b968DV/+8pffz0VdISH8AQAAAAGbPVulvXtrREGBxvTurRGzZ6s0m9uvqKg4OG7cuH0FBUSTTONH3gEAAIBAzZ6t0pkz1X///vhBodpaFc2cqf6SNGOG+OH3DoZ4DQAAAASqulrlDcGvwf79KqiuVnm6tjFhwoRTKysrqyZOnDh49erVJZWVlVWVlZVVP/nJT7qlaxtIDUf+AAAAgEBt26ai1rR/EosXL35bil/zd+WVVw58+eWX16Vr3WgdjvwBAAAAgerZUwdb0472jfAHAAAABGrWLG0pLlZ9YltxsepnzdKWbNXwwgsvlPTo0eO0RYsWdZ05c2b/QYMGDcvWtkOTN+HPzC41szVmVm9msWb6XWBm68xsvZndmtA+0Mz+bGZvmdkjZpa2Q9WZ8uCD0oABUkFB/PnBB3NdEQAAQMfBd62WzZihnXfdpY29eumgmdSrlw7edZc2ZuJmLxUVFQeTnfJ55pln7n3vvfde27dv3/Jdu3atWL9+/Zp0bxtx+XTN32pJ/0vSvU11MLNOku6RNEHSZkmvmNlCd18r6U5Jd7n7w2Y2W9LVkn6R+bI/mQcflKZPl/bujU9v3BiflqTLL89dXQAAAB0B37VSN2OGdnJnzzDkzZE/d3/d3Vu6+HOspPXu/o67H5T0sKRJZmaSzpa0IOp3v6SLMldt2912298+jBrs3RtvBwAAQNvwXQs4Vt6EvxSVS9qUML05ausmaZe7H27UnpSZTTezGjOrqaury1ixzXn33da1AwAAIHV81wKOldXwZ2bPmNnqJI9Jqa4iSZs3056Uu89x95i7x8rKylLcdHr169e6dgAAAKSO71rAsbIa/tz9XHcfnuTxeIqr2Cypb8J0H0lbJe2QdJKZFTZqz1t33CGVlBzdVlISbwcAAEDb8F0LOFZ7O+3zFUmDozt7FkmaLGmhu7ukJZIuifpNlZRqoMyJyy+X5syR+veXzOLPc+ZwATIAAEA68F0LOFbehD8z+4qZbZb0WUlPmtnTUXtvM1skSdE1fddJelrS65J+4+4Nt4K9RdJNZrZe8WsA/yvb76G1Lr9c2rBBqq+PP/NhBAAAkD5812ofnnrqqeOrqqqGFhYWjpk3b17XXNfTkeVN+HP3x9y9j7t3dvce7n5+1L7V3Scm9Fvk7kPc/VR3vyOh/R13H+vug9z9Unc/kIv3AQAAAOBY69atKxo7dmxF4/ZTTjnl4Lx58zZ8+ctffj8XdYUkb8IfAAAAgOybPVulvXtrREGBxvTurRGzZ6s0m9uvqKg4OG7cuH0FBUSTTMunH3kHAAAAkEWzZ6t05kz1378/flCotlZFM2eqvxT/8ffcVod0I14DAAAAgaquVnlD8Guwf78Kqqub/s3s1powYcKplZWVVRMnThy8evXqksrKyqrKysqqn/zkJ93StQ2khiN/AAAAQKC2bVNRa9o/icWLF78txa/5u/LKKwe+/PLL69K1brQOR/4AAACAQPXsqYOtaUf7RvgDAAAAAjVrlrYUF6s+sa24WPWzZmlLtmp44YUXSnr06HHaokWLus6cObP/oEGDhmVr26HhtE8AAAAgUA03damuVvm2bSrq2VMHZ83Slkzc7KWiouJgslM+zzzzzL3vvffea+neHo5F+AMAAAACNmOGdnJnzzBw2icAAAAABIDwBwAAAAABIPwBAAAAHUt9fX295boIZF/0372+qfmEPwAAAKBjWV1XV3ciATAs9fX1VldXd6Kk1U31MXfPYkn5x8zqJG3McRndJe3IcQ3tCeOVOsYqdYxV6zBeqWOsUsdYtQ7jlbp8GKv+7l6WjQ0tW7bs5MLCwl9KGi4O9oSkXtLqw4cPTxszZsz2ZB2CD3/5wMxq3D2W6zraC8YrdYxV6hir1mG8UsdYpY6xah3GK3WMFRDHvwQAAAAAQAAIfwAAAAAQAMJffpiT6wLaGcYrdYxV6hir1mG8UsdYpY6xah3GK3WMFSCu+QMAAACAIHDkDwAAAAACQPjLEjO71MzWmFm9mTV5tykzu8DM1pnZejO7NaF9oJn92czeMrNHzKwoO5Vnn5mVmtni6L0uNrOuSfqcZWYrEh77zeyiaN6vzOwvCfNGZf9dZE8q4xX1O5IwJgsT2tm3ju4zysz+FP29vmZmX02Y1+H3raY+gxLmd472k/XRfjMgYd63o/Z1ZnZ+NuvOhRTG6iYzWxvtR8+aWf+EeUn/HjuyFMbrKjOrSxiXaQnzpkZ/t2+Z2dTsVp59KYzVXQnj9KaZ7UqYF9S+ZWZzzWy7mSX9XTOL+2k0lq+Z2ekJ84LarwBJkrvzyMJD0lBJFZKelxRrok8nSW9LOkVSkaSVkqqieb+RNDl6PVvSNbl+Txkcqx9KujV6faukO1voXyppp6SSaPpXki7J9fvIt/GStKeJdvato/sMkTQ4et1bUq2kk6LpDr1vNfcZlNDnWkmzo9eTJT0Sva6K+neWNDBaT6dcv6ccj9VZCZ9L1zSMVTSd9O+xoz5SHK+rJP1nkmVLJb0TPXeNXnfN9XvK5Vg16n+9pLkB71t/L+l0SaubmD9R0lOSTNJnJP05xP2KB4+GB0f+ssTdX3f3dS10Gytpvbu/4+4HJT0saZKZmaSzJS2I+t0v6aLMVZtzkxR/j1Jq7/USSU+5+96MVpW/WjteH2PfOva9uvub7v5W9HqrpO2SsvKjvHkg6WdQoz6JY7hA0jnRfjRJ0sPufsDd/yJpfbS+jqrFsXL3JQmfS0sl9clyjfkklX2rKedLWuzuO939A0mLJV2QoTrzQWvH6muSHspKZXnI3V9U/B+AmzJJ0gMet1TSSWbWS+HtV4AkTvvMN+WSNiVMb47aukna5e6HG7V3VD3cvVaSoueTW+g/Wcf+j++O6PSOu8yscyaKzCOpjlexmdWY2dKGU2TFvtXsvmVmYxX/l/e3E5o78r7V1GdQ0j7RfrNb8f0olWU7kta+36sVP/rQINnfY0eW6nhdHP19LTCzvq1ctqNI+f1GpxIPlPRcQnNo+1ZLmhrP0PYrQJJUmOsCOhIze0ZSzySzbnP3x1NZRZI2b6a93WpurFq5nl6SRkh6OqH525K2Kf6lfY6kWyRVf7JK80Oaxqufu281s1MkPWdmqyR9mKQf+5Y+3rd+LWmqu9dHzR1u32oklc+aYD6nWpDy+zWzKyTFJJ2Z0HzM36O7v51s+Q4ilfF6QtJD7n7AzGYofoT57BSX7Uha834nS1rg7kcS2kLbt1rCZxaQgPCXRu5+bhtXsVlS34TpPpK2Stqh+GkKhdG/tDe0t1vNjZWZvWdmvdy9NvoCvr2ZVf2jpMfc/VDCumujlwfMbJ6kb6Wl6BxKx3hFpzDK3d8xs+cljZb0qNi3kvXrIulJSf8WnSbUsO4Ot2810tRnULI+m82sUNKJip9ylcqyHUlK79fMzlX8Hx7OdPcDDe1N/D125C/oLY6Xu7+fMHmfpDsTlv1Co2WfT3uF+aM1f0uTJf1zYkOA+1ZLmhrP0PYrQBKnfeabVyQNtvjdF4sU/1Bf6O4uaYni17ZJ0lRJqRxJbK8WKv4epZbf6zHXOkRf6huuZ7tIUtI7gHUgLY6XmXVtOEXRzLpLGi9pLftW0rEqkvSY4teI/LbRvI6+byX9DGrUJ3EML5H0XLQfLZQ02eJ3Ax0oabCkl7NUdy60OFZmNlrSvZIudPftCe1J/x6zVnlupDJevRImL5T0evT6aUnnRePWVdJ5Ovpsj44mlb9DmVmF4jcq+VNCW4j7VksWSpoS3fXzM5J2R/+QF9p+BcTl+o4zoTwkfUXxf2U6IOk9SU9H7b0lLUroN1HSm4r/K91tCe2nKP5Far2k30rqnOv3lMGx6ibpWUlvRc+lUXtM0i8T+g2QtEVSQaPln5O0SvEv5vMlHZ/r95Tr8ZJ0RjQmK6Pnq9m3mhyrKyQdkrQi4TEqlH0r2WeQ4qe2Xhi9Lo72k/XRfnNKwrK3Rcutk/TFXL+XPBirZ6LP+4b9aGHU3uTfY0d+pDBe35e0JhqXJZIqE5b9erTPrZf0T7l+L7keq2j6dkk/aLRccPuW4v8AXBt9bm9W/PraGZJmRPNN0j3RWK5Swh3XQ9uvePBwd5k7pzcDAAAAQEfHaZ8AAAAAEADCHwAAAAAEgPAHAAAAAAEg/AEAAABAAAh/AAAAABAAwh8AoNXMbKqZPWpmG83MzexXua4JAAA0j/AHAPgkrpB0qqTFkj7McS0AACAFhbkuAADQLp3v7vWSZGYX5LoYAADQMo78AQA+ZmafNrM3zOxlM/tUQvt5ZlZvZv8sSQ3BDwAAtB+EPwDAx9z9r5K+JmmkpO9JkpmdLOkBSb9393tyWB4AAGgDwh8A4CjuvlzSrZJuNrNzFQ9+RyR9PaeFAQCANuGaPwBAMndLmiDp95KKJE1w9x25LQkAALQFR/4AAMdwd5f0a0mdJa1092dzXBIAAGgjwh8A4Bhm1lPxo3+vShppZjfkuCQAANBGhD8AwFHMzCTdL+mg4qd+3i3pTjM7LaeFAQCANuGaPwBAYzdJOlfS2e6+08xulfQFSQ+ZWczd95lZlaSqqP9xkvqb2SXR9AvuXpf1qgEAQLMsflkHAACSmY2WtFTSj9z93xLaKxQ/BfQBd7/GzG6X9N0mVnOWuz+f6VoBAEDrEP4AAAAAIABc8wcAAAAAASD8AQAAAEAACH8AAAAAEADCHwAAAAAEgPAHAAAAAAEg/AEAAABAAAh/AAAAABAAwh8AAAAABIDwBwAAAAAB+P9SnKj3kzOGHAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "# BEGIN CODE HERE\n",
    "x1 = [-1, -1, 1, 1]\n",
    "x2 = [-1, 1, -1, 1]\n",
    "x1x2 = [1, -1, -1, 1]\n",
    "xor = [-1, 1, 1, -1]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(12,6))\n",
    "ax.scatter(x1[0], x1x2[0], color=\"red\", label=\" -1\")\n",
    "ax.scatter(x1[3], x1x2[3], color=\"red\", label=\" -1\")\n",
    "ax.scatter(x1[1], x1x2[1], color=\"blue\", label=\" +1\")\n",
    "ax.scatter(x1[2], x1x2[2], color=\"blue\", label=\" +1\")\n",
    "\n",
    "x_mid = [-1, 1]\n",
    "y_mid = [0, 0]\n",
    "\n",
    "ax.plot(x_mid, y_mid, color=\"black\", label=\"decision boundary\")\n",
    "\n",
    "ax.legend(loc=(1.04,0))\n",
    "ax.set_xlabel(\"x1\", fontsize=16)\n",
    "ax.set_ylabel(\"x1x2\", fontsize=16)\n",
    "# END CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "21d15db327a141bbe8d5bf2323358407",
     "grade": true,
     "grade_id": "cell-64bbc4980b5c4edd",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "$x_1x_2 = 0.0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "**Part 2 [5 points]:** Plot the separating line of **Part 1** back in the original Euclidean input space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e6e323e18881c3d6be9b1ff2abd3d8ac",
     "grade": true,
     "grade_id": "cell-9020bbe03ed87cfc",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anirudh/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'x2')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "# BEGIN CODE HERE\n",
    "x1 = [-1, -1, 1, 1]\n",
    "x2 = [-1, 1, -1, 1]\n",
    "xor = [-1, 1, 1, -1]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(12,6))\n",
    "ax.scatter(x1[0], x2[0], color=\"red\", label=\" -1\")\n",
    "ax.scatter(x1[3], x2[3], color=\"red\", label=\" -1\")\n",
    "ax.scatter(x1[1], x2[1], color=\"blue\", label=\" +1\")\n",
    "ax.scatter(x1[2], x2[2], color=\"blue\", label=\" +1\")\n",
    "\n",
    "def f(x):\n",
    "    return 0.001/x\n",
    "\n",
    "x=np.linspace(-1,1,10001)\n",
    "y=f(x)\n",
    "\n",
    "ax.plot(x, y, color=\"black\", label=\"decision boundary\")\n",
    "\n",
    "ax.legend(loc=(1.04,0))\n",
    "# ax.xaxis.set_ticks(np.arange(-1, 1, 0.25))\n",
    "# ax.yaxis.set_ticks(np.arange(-1, 1, 0.25))1\n",
    "ax.set_ylim([-1.2, 1.2])\n",
    "ax.set_xlabel(\"x1\", fontsize=16)\n",
    "ax.set_ylabel(\"x2\", fontsize=16)\n",
    "# END CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 3 [5 points]:** Is the seporater in **Part 1** linear? Is the one in **Part 2** linear? Explain your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8821f5382c580de24c483bd1a0cd4b31",
     "grade": true,
     "grade_id": "cell-119e16472d287f4e",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "The separator in **Part 1** is linear and is non-linear in **Part 2**. Since, we used the kernel trick and made the data linearly separable in **Part 1**, that has a linear decision boundary. But, when we extrapolate the graph back to the euclidean input space. The data is not linearly separable. Hence, the decision boundary has got to be non-linear. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 4 [10 points]:**\n",
    "The key point of the so-called “kernel trick” in SVMs is to learn a classifier that effectively separates the training data in a higher dimensional space without having to explicitly compute the representation $\\phi(\\mathbf{x})$ of every point $\\mathbf{x}$ in the original input space. Instead, all the work is done through the kernel function $K(\\mathbf{x}_i, \\mathbf{x}_i)$, for example, we can use $K(\\mathbf{x}_i, \\mathbf{x}_i) = \\phi(\\mathbf{x}_i)\\phi(\\mathbf{x}_j)$.\n",
    "\n",
    "Show how to compute the squared Euclidean distance in the projected space between any two points $\\mathbf{x}_i$, $\\mathbf{x}_j$ in the original space without explicitly computing the $\\phi$ mapping, instead using the kernel function $K$. In other words, derive $d(\\phi(\\mathbf{x}_i), \\phi(\\mathbf{x}_j))$ into a form using only the kernel function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3beedd96d39e9c464377ae2885f78ba0",
     "grade": true,
     "grade_id": "cell-c6b6512e7d992202",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "$$d(\\phi(\\mathbf{x}_i), \\phi(\\mathbf{x}_j)) = ||\\phi(\\mathbf{x}_i) - \\phi(\\mathbf{x}_j)||^2$$\n",
    "$$d(\\phi(\\mathbf{x}_i), \\phi(\\mathbf{x}_j)) = |\\phi(\\mathbf{x}_i)||\\phi(\\mathbf{x}_i)| + |\\phi(\\mathbf{x}_j)||\\phi(\\mathbf{x}_j)| - 2|\\phi(\\mathbf{x}_i)||\\phi(\\mathbf{x}_j)|$$\n",
    "\n",
    "If we normalize all the values, we can simply say that $|\\phi(\\mathbf{x}_j)||\\phi(\\mathbf{x}_j)| = 1$ and $|\\phi(\\mathbf{x}_i)||\\phi(\\mathbf{x}_i)| = 1$\n",
    "$$d(\\phi(\\mathbf{x}_i), \\phi(\\mathbf{x}_j)) = 1 + 1 - 2|\\phi(\\mathbf{x}_i)||\\phi(\\mathbf{x}_j)|$$\n",
    "$$d(\\phi(\\mathbf{x}_i), \\phi(\\mathbf{x}_j)) = 2(1 - |\\phi(\\mathbf{x}_i)||\\phi(\\mathbf{x}_j)|)$$\n",
    "$$d(\\phi(\\mathbf{x}_i), \\phi(\\mathbf{x}_j)) = 2(1 - K(\\mathbf{x}_i, \\mathbf{x}_j))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[30 points] Problem 3 - SVM with `sklearn`\n",
    "---\n",
    "\n",
    "In this problem, you will get familiar with important practical functions in scikit-learn such as pipeline, grid search, and cross validation. You will experiment with these using support vector machines.\n",
    "\n",
    "Note that grid search can take some time on your laptop, so make sure that your code is correct with a small subset of the training data and search a reasonable number of options.\n",
    "\n",
    "* Use the Sklearn implementation of support vector machines to train a classifier to distinguish Positive and negative sentiments\n",
    "* Experiment with linear, polynomial, and RBF kernels. First, perform a GridSearch over each kernel function and a small set of parameters defined over a wide range to help narrow down the search space.\n",
    "* Then choose the best performing kernel from your coarse scale search and define a narrower set of parameters for random search to further optimize the hyperparameters. Comment on the experiments you ran and optimal hyperparameters you found.\n",
    "Hint: http://scikit-learn.org/stable/modules/grid_search.html\n",
    "* Evaluate classification performance for each model for optimal parameters by testing on a hold-out set.\n",
    "\n",
    "Following is a dataset containing reviews and sentiments associated with it.\n",
    "\n",
    "We will create a SVM Classifier to predict positive or negative sentiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "reviews  = pd.read_csv('./data/reviews.csv')\n",
    "train, test = train_test_split(reviews, test_size=0.2, random_state=5622)\n",
    "X_train = train['reviews']\n",
    "X_test = test['reviews']\n",
    "y_train = train['sentiment']\n",
    "y_test = test['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000 1995 1000 505\n",
      "4000 1000\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train),sum(y_train),len(X_test),sum(y_test))\n",
    "print(len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "832 667\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train[0]), len(X_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 1 [5 points]:**\n",
    "\n",
    "Use `CountVectorizer` to vectorize reviews as dictionary of term frequencies.\n",
    "Define the crossvalidation split using `StratifiedKFold`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ff5c05e229aacfb20ead9cab47a30752",
     "grade": true,
     "grade_id": "cell-ab58d371c35713b4",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/anirudh/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=5, random_state=None, shuffle=True)\n"
     ]
    }
   ],
   "source": [
    "def tokenize(text): \n",
    "    tknzr = TweetTokenizer()\n",
    "    return tknzr.tokenize(text)\n",
    "\n",
    "nltk.download('stopwords')\n",
    "en_stopwords = set(stopwords.words(\"english\")) \n",
    "\n",
    "# CREATE CountVectorizer using sklearn.feature_extraction.text.CountVectorizer\n",
    "# Hint: use the above tokenize function\n",
    "# Hint: play with different parameters, in particular, min_df can help with generalizability\n",
    "# YOUR CODE HERE\n",
    "# BEGIN CODE HERE\n",
    "\n",
    "# corpus = []\n",
    "# for idx, row in X_train.iteritems():\n",
    "#     corpus_i = tokenize(X_train[idx])\n",
    "#     corpus += corpus_i\n",
    "# corpus = set(corpus)\n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer(max_df=1.0, min_df=1, stop_words=en_stopwords, tokenizer=tokenize)\n",
    "X_train_tokenized = vectorizer.fit_transform(X_train)\n",
    "# print(vectorizer.get_feature_names())\n",
    "# END CODE HERE\n",
    "\n",
    "# split dataset using StratifiedKFold into 5 splits using sklearn.model_selection.StratifiedKFold.\n",
    "# YOUR CODE HERE\n",
    "# BEGIN CODE HERE\n",
    "kfolds = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "kfolds.get_n_splits(X_train, y_train)\n",
    "print(kfolds)\n",
    "# END CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 2 [10 points]:**\n",
    "* Create a pipeline with our `CountVectorizer` object in **Part 1** and an SVM Classifier.\n",
    "* Create and fit a `GridSearchCV` object with the following parameter values:\n",
    "  * Linear kernel, $C = 0.01, 1.0, 10.0$\n",
    "  * Polynomial kernel, $\\text{degree} = 2, 3$, $\\gamma = 0.1, 0.5, 1$\n",
    "  * RBF kernel, $\\gamma = 0.1, 0.5, 1$\n",
    "* Report accuracy on the best estimator from our `GridSearchCV` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "88d870b8bb537716016ae1577d22d90b",
     "grade": true,
     "grade_id": "cell-a3dd5b25a9ce8feb",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:  8.9min finished\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(5622)\n",
    "# Define pipeline using make_pipeline with vectorizer and SVM Classifier\n",
    "# YOUR CODE HERE\n",
    "# BEGIN CODE HERE\n",
    "svm_clf = SVC()\n",
    "pipeline_svm = Pipeline(steps=[('vect', vectorizer), ('model', svm_clf)])\n",
    "\n",
    "parameters = [\n",
    "  {'model__C': [0.01, 1.0, 10.0], 'model__kernel': ['linear']},\n",
    "  {'model__gamma': [0.1, 0.5, 1], 'model__kernel': ['poly'], 'model__degree': [2, 3]},\n",
    "  {'model__gamma': [0.1, 0.5, 1], 'model__kernel': ['rbf']},\n",
    "  \n",
    " ]\n",
    "# END CODE HERE\n",
    "\n",
    "# Create GridSearchCV with pipeline and the grid search parameters given above,\n",
    "# using \"accuracy\" for scoring.\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# BEGIN CODE HERE\n",
    "grid_svm = GridSearchCV(pipeline_svm, param_grid=parameters, cv=kfolds, scoring=\"accuracy\", verbose=1)\n",
    "# END CODE HERE\n",
    "\n",
    "\n",
    "# For debugging purposes, it makes sense to use a smaller set of training set to speed up the grid search progress\n",
    "_ = grid_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "089068689cee53bba013581b01e8c6cc",
     "grade": true,
     "grade_id": "cell-47833f7ec14a9d22",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model__C': 0.01, 'model__kernel': 'linear'}\n",
      "0.87925\n"
     ]
    }
   ],
   "source": [
    "# Report best parameters and CV score from grid search\n",
    "# YOUR CODE HERE\n",
    "# BEGIN CODE HERE\n",
    "print(grid_svm.best_params_)\n",
    "print(grid_svm.best_score_)\n",
    "\n",
    "# END CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 3 [10 points]:**\n",
    "\n",
    "Choose the best performing kernel and parameter values from your coarse scale grid search and use them to set up a narrower range of parameter values. We will use randomized grid search to sample a fixed number of these candidate parameter sets for cross validation. The number of sampled parameter sets `n_iter` provides a trade-off between computational cost and quality of the \"optimal\" parameters. Feel free to experiment with different values of this parameter, but please change it back to `n_iter = 5` before submitting your assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "59e134fffac3e070713e01dd8de977f6",
     "grade": true,
     "grade_id": "cell-e1116a343a3e645a",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:   48.5s finished\n"
     ]
    }
   ],
   "source": [
    "# Set random seed for deterministic output\n",
    "np.random.seed(5622)\n",
    "\n",
    "# Set param_grid to a dictionary containing parameter values for fine scale search.\n",
    "# YOUR CODE HERE\n",
    "param_grid = {\n",
    "  'model__C': [0.008, 0.009, 0.0095, 0.01, 0.02, 0.03, 0.04], 'model__kernel': ['linear']\n",
    "}\n",
    "\n",
    "# Create randomized parameter search over fine scale grid;\n",
    "# Do NOT change the value of n_iter in the submitted version of your notebook.\n",
    "n_iter = 5\n",
    "random_svm = RandomizedSearchCV(pipeline_svm,\n",
    "                                param_grid,\n",
    "                                n_iter=n_iter,\n",
    "                                cv = kfolds,\n",
    "                                scoring=\"accuracy\",\n",
    "                                verbose=1,   \n",
    "                                n_jobs=-1)\n",
    "\n",
    "_ = random_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4b5d5fa7e1321d87c5eef4b928afaf25",
     "grade": true,
     "grade_id": "cell-39b5a8b9e508cf0e",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model__kernel': 'linear', 'model__C': 0.009}\n",
      "0.879\n"
     ]
    }
   ],
   "source": [
    "# Report best parameters and CV score from grid search\n",
    "# YOUR CODE HERE\n",
    "print(random_svm.best_params_)\n",
    "print(random_svm.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_results(model, X, y):\n",
    "    pred = model.predict(X)        \n",
    "    acc = accuracy_score(y, pred)\n",
    "    f1 = f1_score(y, pred)\n",
    "    prec = precision_score(y, pred)\n",
    "    rec = recall_score(y, pred)\n",
    "    result = {'f1': f1, 'acc': acc, 'precision': prec, 'recall': rec}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': 0.8792934249263985,\n",
       " 'acc': 0.877,\n",
       " 'precision': 0.8715953307392996,\n",
       " 'recall': 0.8871287128712871}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_results(random_svm.best_estimator_, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 4 [5 points]:**\n",
    "\n",
    "Explain the overall procedure, and report the final result including which hyperparameter values were chosen. Make sure to explain your reasoning in choosing a refined parameter search space in **Part 3**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "651d32596f089e5e6a6cc978c6f79cd6",
     "grade": true,
     "grade_id": "cell-6fecb92ed6ad5abe",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "* We use the count vectorizer to tokenize the text data and to represent that as a sparse matrix.\n",
    "* Then, we create a pipeline for the vectorizer and a svm classifier with a parameter grid to do a grid search.\n",
    "* The point of the pipeline is to automate the vectorization of the textual data.\n",
    "* In the grid Search, we try out all the different parameters for an SVM, like the value of C, the kernel type, gamma value. We could do the paramter search for the vectorizer as well. Setting different max_dif and min_dif values.\n",
    "* The linear kernel with C = 0.1 performs the best among the parameters specified. So, for the narrower search, we can omit all the other kernels and the values of C which didn't give a better value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional survey.\n",
    "***\n",
    "\n",
    "We are always interested in your feedback. At the end of each homework, there is a simple anonymous feedback [survey](https://forms.gle/bEaNM6G2qFRKhU4Z9) to solicit your feedback for how to improve the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
